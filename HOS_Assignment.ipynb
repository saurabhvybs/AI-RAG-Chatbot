{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhvybs/AI-RAG-Chatbot/blob/main/HOS_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J0INoJq6Ak_l",
      "metadata": {
        "id": "J0INoJq6Ak_l"
      },
      "source": [
        "# Data Science Internship Assignment: Exploring Text Splitters in LangChain\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "This assignment focuses on text-splitting strategies using the LangChain framework. Text splitters are essential for dividing large texts into smaller, manageable chunks for processing with language models. In this assignment, you will use several built-in LangChain splitters to split sample texts and analyze the results.\n",
        "\n",
        "You will work with the following splitters:\n",
        "- Split text based on a fixed character count.\n",
        "- Split text recursively, preserving semantic boundaries like sentences.\n",
        "- Split text based on semantic meaning (requires a model for embeddings).\n",
        "- Split Markdown text based on headers.\n",
        "- Split HTML text based on headers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-dbvtTQwAk_r",
      "metadata": {
        "id": "-dbvtTQwAk_r"
      },
      "source": [
        "**Sample Texts**\n",
        "\n",
        "Below are sample texts for each splitter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uv82V-xGAk_s",
      "metadata": {
        "id": "Uv82V-xGAk_s"
      },
      "outputs": [],
      "source": [
        "plain_text = \"\"\"\n",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n",
        "\n",
        "Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DL04uBEYAk_s",
      "metadata": {
        "id": "DL04uBEYAk_s"
      },
      "source": [
        "- **Markdown Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JRHYBca_Ak_t",
      "metadata": {
        "id": "JRHYBca_Ak_t"
      },
      "outputs": [],
      "source": [
        "markdown_text = \"\"\"\n",
        "# Introduction\n",
        "This is the introduction section.\n",
        "\n",
        "## Subsection 1\n",
        "This is the first subsection under the introduction.\n",
        "\n",
        "### Details\n",
        "Here are some details about subsection 1.\n",
        "\n",
        "## Subsection 2\n",
        "This is the second subsection.\n",
        "\n",
        "# Conclusion\n",
        "This is the conclusion section.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nU1A3ekbAk_t",
      "metadata": {
        "id": "nU1A3ekbAk_t"
      },
      "source": [
        "- **HTML Text**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kGNs4L7EAk_t",
      "metadata": {
        "id": "kGNs4L7EAk_t"
      },
      "outputs": [],
      "source": [
        "html_text = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "<h1>Introduction</h1>\n",
        "<p>This is the introduction section.</p>\n",
        "<h2>Subsection 1</h2>\n",
        "<p>This is the first subsection under the introduction.</p>\n",
        "<h3>Details</h3>\n",
        "<p>Here are some details about subsection 1.</p>\n",
        "<h2>Subsection 2</h2>\n",
        "<p>This is the second subsection.</p>\n",
        "<h1>Conclusion</h1>\n",
        "<p>This is the conclusion section.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_a45GO_3Ak_u",
      "metadata": {
        "id": "_a45GO_3Ak_u"
      },
      "source": [
        "**Task 1: Character-Based Splitting**\n",
        "\n",
        "Use a Character based splitter to split the `plain_text` into chunks of approximately 100 characters, with a chunk overlap of 20 characters. Print the first three chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pt7nIVHBAk_v",
      "metadata": {
        "id": "Pt7nIVHBAk_v"
      },
      "source": [
        "**Task 2: Recursive Character Splitting**\n",
        "\n",
        "Use Recursive Character splitter to split the `plain_text` into chunks of approximately 100 characters, with a chunk overlap of 20 characters. This splitter attempts to preserve semantic boundaries (e.g., sentences). Print the first three chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QOEe8U4oAk_w",
      "metadata": {
        "id": "QOEe8U4oAk_w"
      },
      "source": [
        "**Task 3: Semantic Chunking**\n",
        "\n",
        "Use the Semantic Chunker to split the `plain_text` based on semantic meaning. You will need to use an embedding model for this splitter. Print the first three chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QoRZDcVjAk_w",
      "metadata": {
        "id": "QoRZDcVjAk_w"
      },
      "source": [
        "**Task 4: Markdown Header Splitting**\n",
        "\n",
        "Use a Markdown Splitter to split the `markdown_text` based on Markdown headers. Print the resulting chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aKR5YObLAk_x",
      "metadata": {
        "id": "aKR5YObLAk_x"
      },
      "source": [
        "**Task 5: HTML Text Splitting**\n",
        "\n",
        "Use a HTML Text Splitter to split the `html_text` based on HTML headers. Print the resulting chunks.\n",
        "\n",
        "Hint: Specify the headers to split on, such as `h1`, `h2`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f763627",
      "metadata": {
        "id": "9f763627"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are basic imports needed for the tasks."
      ],
      "metadata": {
        "id": "w1oWTfSGkRgI"
      },
      "id": "w1oWTfSGkRgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-experimental openai sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LUW8pvSTke6H"
      },
      "id": "LUW8pvSTke6H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING TEXT FOR PROCESSING"
      ],
      "metadata": {
        "id": "faQA5jp9nBHu"
      },
      "id": "faQA5jp9nBHu"
    },
    {
      "cell_type": "code",
      "source": [
        "plain_text = \"\"\"\n",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n",
        "\n",
        "Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
        "\"\"\"\n",
        "\n",
        "markdown_text = \"\"\"\n",
        "# Introduction\n",
        "This is the introduction section.\n",
        "\n",
        "## Subsection 1\n",
        "This is the first subsection under the introduction.\n",
        "\n",
        "### Details\n",
        "Here are some details about subsection 1.\n",
        "\n",
        "## Subsection 2\n",
        "This is the second subsection.\n",
        "\n",
        "# Conclusion\n",
        "This is the conclusion section.\n",
        "\"\"\"\n",
        "\n",
        "html_text = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "<h1>Introduction</h1>\n",
        "<p>This is the introduction section.</p>\n",
        "<h2>Subsection 1</h2>\n",
        "<p>This is the first subsection under the introduction.</p>\n",
        "<h3>Details</h3>\n",
        "<p>Here are some details about subsection 1.</p>\n",
        "<h2>Subsection 2</h2>\n",
        "<p>This is the second subsection.</p>\n",
        "<h1>Conclusion</h1>\n",
        "<p>This is the conclusion section.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a8ScZglHkvtO"
      },
      "id": "a8ScZglHkvtO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Task 1: Splitting Text using `CharacterTextSplitter`\n",
        "In this task, we use the **CharacterTextSplitter** to break a large block of text into smaller chunks.  \n",
        "This helps in preparing text for downstream NLP/LLM tasks where input size is limited.  \n",
        "We configure **chunk size** and **overlap** to control granularity."
      ],
      "metadata": {
        "id": "2EczjD1nm0N9"
      },
      "id": "2EczjD1nm0N9"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "OF4zG4D-k7aq"
      },
      "id": "OF4zG4D-k7aq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\\n\",\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "char_chunks = char_splitter.split_text(plain_text)\n",
        "\n",
        "print(\"--- First Three Chunks (Character-Based) ---\")\n",
        "for i, chunk in enumerate(char_chunks[:3]):\n",
        "    print(f\"Chunk {i+1}: \\\"{chunk}\\\" (Length: {len(chunk)})\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IxVtzfdelG8m"
      },
      "id": "IxVtzfdelG8m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Task 2: Recursive Splitting with `RecursiveCharacterTextSplitter`\n",
        "Here, we apply the **RecursiveCharacterTextSplitter**, which intelligently tries different separators (`\\n`, space, punctuation, etc.) to split text.  \n",
        "This ensures cleaner splits compared to a plain character-based approach."
      ],
      "metadata": {
        "id": "pMny9_O2mZLd"
      },
      "id": "pMny9_O2mZLd"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "recursive_chunks = recursive_splitter.split_text(plain_text)\n",
        "\n",
        "print(\"--- First Three Chunks (Recursive) ---\")\n",
        "for i, chunk in enumerate(recursive_chunks[:3]):\n",
        "    print(f\"Chunk {i+1}: \\\"{chunk}\\\" (Length: {len(chunk)})\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KZO7jjV_mkl7"
      },
      "id": "KZO7jjV_mkl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Task 3: Parsing Markdown with `MarkdownHeaderTextSplitter`\n",
        "This task demonstrates splitting **Markdown documents** by headers like `#`, `##`, and `###`.  \n",
        "The splitter groups text under each header so that hierarchy is preserved for structured documents."
      ],
      "metadata": {
        "id": "6UuMaPvdnZjw"
      },
      "id": "6UuMaPvdnZjw"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Using a free, open-source embedding model from Hugging Face\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "semantic_splitter = SemanticChunker(embeddings)\n",
        "semantic_chunks = semantic_splitter.split_text(plain_text)\n",
        "\n",
        "print(\"--- First Three Chunks (Semantic) ---\")\n",
        "for i, chunk in enumerate(semantic_chunks[:3]):\n",
        "    print(f\"Chunk {i+1}: \\\"{chunk}\\\"\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YQlcktNcni8S"
      },
      "id": "YQlcktNcni8S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Task 4: Parsing HTML with `HTMLHeaderTextSplitter`\n",
        "We now work with **HTML documents**, splitting based on tags such as `<h1>` and `<h2>`.  \n",
        "This is useful when dealing with webpages, reports, or any HTML-based content."
      ],
      "metadata": {
        "id": "zqjYgJcXrGml"
      },
      "id": "zqjYgJcXrGml"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "markdown_chunks = markdown_splitter.split_text(markdown_text)\n",
        "\n",
        "print(\"--- All Chunks (Markdown) ---\")\n",
        "for chunk in markdown_chunks:\n",
        "    print(f\"Content: \\\"{chunk.page_content}\\\"\")\n",
        "    print(f\"Metadata: {chunk.metadata}\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uiVAe1curWlP"
      },
      "id": "uiVAe1curWlP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# üìù Task 5: Comparing Splitters\n",
        "Finally, we compare how different splitters behave:\n",
        "- **CharacterTextSplitter** ‚Üí Simple, fixed-size chunks.  \n",
        "- **RecursiveCharacterTextSplitter** ‚Üí Smarter, cleaner breaks.  \n",
        "- **Markdown/HTML Splitters** ‚Üí Preserve document hierarchy."
      ],
      "metadata": {
        "id": "QkkFl_9DsKBb"
      },
      "id": "QkkFl_9DsKBb"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import HTMLHeaderTextSplitter\n",
        "\n",
        "headers_to_split_on = [\n",
        "    (\"h1\", \"Header 1\"),\n",
        "    (\"h2\", \"Header 2\"),\n",
        "    (\"h3\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "html_chunks = html_splitter.split_text(html_text)\n",
        "\n",
        "print(\"--- All Chunks (HTML) ---\")\n",
        "for chunk in html_chunks:\n",
        "    print(f\"Content: \\\"{chunk.page_content}\\\"\")\n",
        "    print(f\"Metadata: {chunk.metadata}\\n\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KuqDzXfJsUWn"
      },
      "id": "KuqDzXfJsUWn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}